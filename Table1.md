## Table A. From values to criteria and their manifestations
<br>
Summary of the specific criteria that relate to each value considered in our ML assessment framework. These criteria are then translated into specific manifestations in the form of signifiers (orange), process-oriented practices (olive) or quantifiable indicators (magenta).<br><br>

| Value       | Criteria  | Manifestations|
| ----------- |---------- | --------------
| Privacy     | 1. **Consent for data usage** ([[1]](references.md#GDPR2018), [[2]](references.md#fjeld2020), [[3]](references.md#krafft2020))  <br> 2. **Data protection** ([[2]](references.md#fjeld2020),[[3]](references.md#krafft2020),[[4]](references.md#floridi2019))<br> 3. **Control over data / ability to restrict processing** ([[1]](references.md#GDPR2018), [[2]](references.md#fjeld2020))<br> 4. **Right to rectification** ([[1]](references.md#GDPR2018), [[2]](references.md#fjeld2020), [[3]](references.md#krafft2020)) <br> 5. **Right to erase the data** ([[1]](references.md#GDPR2018), [[2]](references.md#fjeld2020), [[3]](references.md#krafft2020))<br> 6. **Right of access by data subject, data agency** ([[1]](references.md#GDPR2018), [[5]](references.md#IEEE2019)) | - <span style="color:orange">Written declaration of consent</span>([[1]](references.md#GDPR2018)) <br> - <span style="color:orange">Description of what data is collected</span>([[6]](references.md#mehldau2007)) <br> - <span style="color:orange">Description of how data is handled</span> ([[6]](references.md#mehldau2007)) <br> - <span style="color:orange">Purpose statement of data collection</span> ([[6]](references.md#mehldau2007)) <br> - <span style="color:orange">Statement of how long the data is kept</span> ([[6]](references.md#mehldau2007)) <br> - <span style="color:olive">For and submission mechanisms to object data collection and to make complaints</span> ([[7]](references.md#blazevic2021)) <br> - <span style="color:olive">Obfuscation of data</span> ([[3]](references.md#krafft2020))                                           
| Security    | 1. **Resilience to attacks**: protection of privacy ([[8]](references.md#microsoftai2018), [[9]](references.md#hidalgo2021), [[10]](references.md#wachter2019)), vulnerabilities, fallback plans ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[11]](references.md#morley2020), [[12]](references.md#googleai2018)) <br>2. **Predictability** ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[13]](references.md#europeancommissionEthicsAI2019)) <br> 3. **Robustness / reliability**: prevent manipulation ([[3]](references.md#krafft2020)) | AGAINST INTEGRITY THREATS ([[14]](references.md#xiong2021)): <br> Training time ([[14]](references.md#xiong2021)). Ex.:<br><span style="color:olive"> -Data sanitization[^1] ([[15]](references.md#biggio2018), [[16]](references.md#cretu2008))<br> -Robust learning[^2] ([[15]](references.md#biggio2018), [[17]](references.md#globerson2006))<br></span><br> Prediction time ([[14]](references.md#xiong2021)):<br> <span style="color:olive"> - Model enhancement ([[15]](references.md#biggio2018), [[18]](references.md#lyu2015), [[19]](references.md#goodfellow2014), [[20]](references.md#papernot2016))<br> - Adversarial learning[^3]<br> - Gradient masking[^4]<br> - Defensive Distillation[^5]</span> <br><br> AGAINST PRIVACY THREATS ([[14]](references.md#xiong2021)): <br> Mitigation techniques ([[21]](references.md#nasr2018)):<br> <span style="color:olive"> - Restrict prediction vector to top k classes[^6] ([[22]](references.md#shokri2017))<br> - Coarsen the precision of the prediction vector[^7] ([[22]](references.md#shokri2017))<br> - Increase entropy of the prediction vector[^8] ([[22]](references.md#shokri2017))<br> - Use regularization[^9]([[22]](references.md#shokri2017), [[23]](references.md#kaya2020))<br></span>  <br>Differential privacy mechanisms ([[21]](references.md#nasr2018)): <br>    <span style="color:olive"> - Differential privacy[^10] ([[24]](references.md#ye2021), [[25]](references.md#dwork2006)). Ex.:<br> - Adversarial regularization[^11] ([[21]](references.md#nasr2018))<br> - MemGuard[^12] ([[26]](references.md#jia2019)</span> 
| Performance | 1. **Correctness of predictions** ([[2]](references.md#fjeld2020), [[13]](references.md#europeancommissionEthicsAI2019), [[27]](references.md#bihrane2021)) <br> 2. **Memory efficiency** ([[3]](references.md#krafft2020)), [[27]](references.md#bihrane2021))<br> 3. **Training efficiency** ([[27]](references.md#bihrane2021)) <br> 4. **Energy efficiency** ([[3]](references.md#krafft2020)), [[27]](references.md#bihrane2021)) <br> 5. **Data efficiency** ([[27]](references.md#bihrane2021))  |   - <span style="color:magenta">Accuracy ([[28]](references.md#mitchell2019), [[29]](references.md#wexler2019))</span> <br> - <span style="color:magenta">False Positive and Negative rates ([[28]](references.md#mitchell2019), [[29]](references.md#wexler2019))</span> <br> - <span style="color:magenta">False Discovery and Omission rates ([[28]](references.md#mitchell2019))</span> <br> - <span style="color:magenta">Mean and median error ([[29]](references.md#wexler2019))</span> <br> - <span style="color:magenta">R2 score ([[30]](references.md#bird2020))</span> <br> - <span style="color:magenta">Precision and recall rates ([[29]](references.md#wexler2019))</span><br> - <span style="color:magenta">Area under ROC curve (AUC) ([[30]](references.md#bird2020))</span> <br> - <span style="color:magenta">Estimation of energy consumption through ([[31]](references.md#garciamartin2019)):<br></span> <span style="color:black"> <br>- performance counters<br> - simulation<br> - instruction- or architecture-level estimations<br> - real-time estimation</span> <br><br>- <span style="color:magenta">Estimation of GPU memory consumption ([[32]](references.md#gao2020), [[33]](references.md#mahendran2021))</span> <br> - <span style="color:magenta">Wall-clock training time ([[34]](references.md#assran2020), [[35]](references.md#dalton2020))</span>  
|Respect for public interest | 1. **Desirability of technology** ([[36]](references.md#chasalow2021), [[37]](references.md#abebe2020), [[38]](references.md#keyes2019))<br> 2. **Benefit to society** ([[2]](references.md#fjeld2020), [[4]](references.md#floridi2019), [[11]](references.md#morley2020), [[39]](references.md#floridi2018))<br> 3. **Environmental impact** ([[3]](references.md#krafft2020), [[40]](references.md#bender2021)) | - <span style="color:olive">Diverse and inclusive forum for discussion ([[2]](references.md#fjeld2020), [[41]](references.md#frenchminister2019))</span> <br> - <span style="color:orange">Measure of social and environmental impact ([[11]](references.md#morley2020), [[40]](references.md#bender2021)), [[42]](references.md#raji2020))</span> 
|Fairness| 1. **Individual fairness**[^13] ([[25]](references.md#dwork2006), [[43]](references.md#mehrabi2021), [[44]](references.md#barredoarrieta2020), [[45]](references.md#kusner2017))<br> 2. **Demographic parity**[^14] ([[9]](references.md#hidalgo2021), [[25]](references.md#dwork2006), [[43]](references.md#mehrabi2021),[[44]](references.md#barredoarrieta2020), [[45]](references.md#kusner2017), [[46]](references.md#harrison2020), [[47]](references.md#srivastava2019), [[48]](references.md#kearns2018), [[49]](references.md#verma2018))<br> 3. **Conditional statistical parity**[^15] ([[43]](references.md#mehrabi2021), [[49]](references.md#verma2018))<br> 4. **Equality of opportunity**[^16]([[43]](references.md#mehrabi2021), [[50]](references.md#hardt2016), [[51]](references.md#vanBerkel2021)) <br> 5. **Equalized odds**[^17] ([[43]](references.md#mehrabi2021))<br> 6. **Treatment equality**[^18] ([[43]](references.md#mehrabi2021), [[52]](references.md#berk2017))<br> 7. **Test fairness**[^19] ([[43]](references.md#mehrabi2021), [[49]](references.md#verma2018), [[53]](references.md#chouldechova2016))<br> 8. **Procedural fairness**[^20] ([[43]](references.md#mehrabi2021), [[45]](references.md#kusner2017), [[54]](references.md#grgichlaca2018)) | - <span style="color:magenta">Accuracy across groups ([[11]](references.md#morley2020), [[46]](references.md#harrison2020), [[53]](references.md#chouldechova2016), [[55]](references.md#kleinberg2016))</span><br> - <span style="color:magenta">False positive and negative rates across groups ([[43]](references.md#mehrabi2021), [[53]](references.md#chouldechova2016), [[55]](references.md#kleinberg2016), [[56]](references.md#wang2020), [[57]](references.md#saleiro2018))</span> <br> - <span style="color:magenta">False discovery and omission rates across groups ([[28]](references.md#mitchell2019), [[57]](references.md#saleiro2018))</span><br> - <span style="color:magenta">Pinned AUC ([[28]](references.md#mitchell2019), [[58]](references.md#dixon2018))</span><br> - <span style="color:olive">Debiasing algorithms ([[59]](references.md#bellamy2018))</span><br> - <span style="color:olive">Election of protected classes based on user considerations ([[54]](references.md#grgichlaca2018))</span> 
| Non-discrimination| 1. **Quality and integrity of data** ([[2]](references.md#fjeld2020), [[9]](references.md#hidalgo2021), [[11]](references.md#morley2020), [[60]](references.md#stuartgeiger2020), [[61]](references.md#paullada2020)) <br> 2. **Inclusiveness in design** ([[2]](references.md#fjeld2020), [[11]](references.md#morley2020), [[13]](references.md#europeancommissionEthicsAI2019))<br> 3. **Accessibility** ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[11]](references.md#morley2020), [[27]](references.md#bihrane2021)) | - <span style="color:olive">Inclusive data generation process ([[3]](references.md#krafft2020), [[11]](references.md#morley2020), [[36]](references.md#chasalow2021), [[60]](references.md#stuartgeiger2020))</span> <br> - <span style="color:magenta">Analysis of data for potential biases, data quality assessment ([[2]](references.md#fjeld2020),[[3]](references.md#krafft2020), [[9]](references.md#hidalgo2021), [[43]](references.md#mehrabi2021), [[62]](references.md#gebru2020))</span><br>- <span style="color:olive">Diversity of participant in development process ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[63]](references.md#lee2019), [[64]](references.md#zhouWeb))</span><br> - <span style="color:olive">Access to code and technology to all ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[11]](references.md#morley2020), [[27]](references.md#bihrane2021))</span>
| Transparency| 1. **Interpretability of data and models** ([[27]](references.md#bihrane2021), [[65]](references.md#royalsociety2019))<br> 2. **Enabling human oversight of operations** ([[2]](references.md#fjeld2020), [[11]](references.md#morley2020))<br>3. **Accessibility of data and algorithm** ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[65]](references.md#royalsociety2019))<br> 4. **Traceability** [[11]](references.md#morley2020)<br>5. **Reproducibility** [[27]](references.md#bihrane2021)| - <span style="color:orange">Description of data generation process ([[3]](references.md#krafft2020), [[11]](references.md#morley2020), [[36]](references.md#chasalow2021), [[60]](references.md#stuartgeiger2020), [[62]](references.md#gebru2020), [[66]](references.md#bender2018))</span><br> - <span style="color:orange">Disclosure of origin and properties of models and data ([[3]](references.md#krafft2020), [[28]](references.md#mitchell2019), [[65]](references.md#royalsociety2019))</span><br> - <span style="color:olive">Open access to data and algorithms ([[2]](references.md#fjeld2020), [[3]](references.md#krafft2020), [[27]](references.md#bihrane2021), [[65]](references.md#royalsociety2019))</span><br> - <span style="color:orange">Notification of usage/interaction ([[2]](references.md#fjeld2020))</span><br> - <span style="color:orange">Regular reporting ([[2]](references.md#fjeld2020))</span>
|Explainability| 1. **Ability to understand AI systems and the decision reached** ([[4]](references.md#floridi2019), [[13]](references.md#europeancommissionEthicsAI2019), [[27]](references.md#bihrane2021), [[39]](references.md#floridi2018), [[65]](references.md#royalsociety2019), [[67]](references.md#OECD2019))<br> 2. **Traceability** ([[11]](references.md#morley2020)) <br> 3. **Enable evaluation** ([[2]](references.md#fjeld2020), [[11]](references.md#morley2020)) | - <span style="color:olive">Interpretability by design ([[44]](references.md#barredoarrieta2020))</span><br> - <span style="color:olive">Post-hoc explanations ([[44]](references.md#barredoarrieta2020))</span>
|Contestability | 1. **Enable argumentation / negotiation against a decision** ([[2]](references.md#fjeld2020), [[13]](references.md#europeancommissionEthicsAI2019), [[65]](references.md#royalsociety2019), [[68]](references.md#balayn2021Edri), [[69]](references.md#kyunglee2017), [[70]](references.md#alfrink2020), [[71]](references.md#kalluri2020), [[72]](references.md#lyons2021)) <br> 2. **Citizen empowerment** ([[13]](references.md#europeancommissionEthicsAI2019), [[68]](references.md#balayn2021Edri), [[71]](references.md#kalluri2020))| - <span style="color:orange">Information of who determines and what constitutes a contestable decision and who is accountable ([[72]](references.md#lyons2021))</span><br> - <span style="color:orange">Determination of who can contest the decision (subject or representative) ([[72]](references.md#lyons2021))</span><br> - <span style="color:orange">Indication of type of review in place ([[72]](references.md#lyons2021))</span><br> - <span style="color:orange">Information regarding the contestability workflow ([[72]](references.md#lyons2021))</span><br> - <span style="color:olive">Mechanisms for users to ask questions and record disagreements with system behavior ([[73]](references.md#hirsch2017), [[74]](references.md#mitra2021))</span>
| Human Control | 1. **User/collective influence** ([[27]](references.md#bihrane2021), [[69]](references.md#kyunglee2017)) <br> 2. **Human review of automated decision** ([[2]](references.md#fjeld2020))<br> 3. **Choice of how and whether to delegate** ([[2]](references.md#fjeld2020))| - <span style="color:olive">Continuous monitoring of system to intervene ([[2]](references.md#fjeld2020), [[13]](references.md#europeancommissionEthicsAI2019), [[75]](references.md#teliaai2019))</span><br> - <span style="color:olive">Establishment levels of human discretion during the use of the system ([[8]](references.md#microsoftai2018), [[13]](references.md#europeancommissionEthicsAI2019))</span><br> - <span style="color:olive">Ability to override the decision made by the system ([[13]](references.md#europeancommissionEthicsAI2019))</span>
| Human Agency| 1. **Respect for human autonomy** ([[2]](references.md#fjeld2020), [[11]](references.md#morley2020), [[13]](references.md#europeancommissionEthicsAI2019))<br> 2. **Power to decide. Ability to make informed autonomous decision** ([[13]](references.md#europeancommissionEthicsAI2019), [[27]](references.md#bihrane2021))<br> 3. **Ability to opt out of an automated decision** ([[2]](references.md#fjeld2020), [[13]](references.md#europeancommissionEthicsAI2019))|- <span style="color:orange">Give knowledge and tools to comprehend and interact with AI system ([[13]](references.md#europeancommissionEthicsAI2019))</span><br> - <span style="color:olive">Opportunity to self-assess the system ([[13]](references.md#europeancommissionEthicsAI2019))</span>


[Back to main page](index.md)

[^1]: It ensures data soundness by identifying abnormal input samples and by removing them ([[14]](#xiong2021))
[^2]: It ensures that algorithms are trained on statistically robust datasets, with little sensitivity to outliers ([[14]](#xiong2021))
[^3]: Adversarial samples are introduced to the training set ([[14]](#xiong2021))
[^4]: Input gradients are modified to enhance model robustness ([[14]](#xiong2021))
[^5]: The dimensionality of the network is reduced ([[14]](#xiong2021))
[^6]: Applicable when the number of classes is very large. Even if the model only outputs the most likely k classes, it will still be useful ([[22]](#shokri2017))
[^7]: It consists in rounding the classification probabilities down ([[22]](#shokri2017))
[^8]: Modification of  the softmax layer (in neural networks) to increase its normalizing temperature ([[22]](#shokri2017))
[^9]: Technique to avoid overfitting in ML that penalizes large parameters by adding a regularization factor $\lambda$ to the loss function ([[22]](#shokri2017))
[^10]: It prevents any adversary from distinguishing the predictions of a model when its training dataset is used compared to when other dataset is used ([[24]](#ye2021))
[^11]: Membership privacy is modeled as a min-max optimization problem, where a model is trained to achieve minimum loss of accuracy and maximum robustness against the strongest inference attack ([[21]](#nasr2018))
[^12]: Noise is added to the confidence vector of the attacker so as to mislead the attacker's classifier ([[26]](#jia2019))
[^13]: Similar individuals should be treated in a similar way. Diverging definitions state that: two individuals that are similar with respect to a common metric should receive the same outcome (*fairness through awareness*); or any protected attribute should not be used when making a decision (*fairness through unawareness*); or the outcome obtained by an individual should be the same if this individual belonged to a counterfactual world or group (*counterfactual fairness*) ([[43]](#mehrabi2021))
[^14]: The probability of getting a positive outcome should be the same whether the individual belongs to a protected group or not ([[43]](#mehrabi2021))
[^15]: Given a set of factors L, individuals belonging to the protected or unprotected group should have the same probability of getting a positive outcome ([[43]](#mehrabi2021))
[^16]: The probability for a person from class A (positive class) of getting a positive outcome, which should be the same regardless of the group (protected group or not) that the individual belongs to  ([[43]](#mehrabi2021))
[^17]: The probability for a person from class A (positive class) of getting a positive outcome and the probability for a person from class B (negative class) of getting a negative outcome should be the same ([[43]](#mehrabi2021))
[^18]: The ratio of false positives and negatives has to be the same for both groups ([[43]](#mehrabi2021))
[^19]: For any probability score S, the probability of correctly belonging to the positive class should be the same for both the protected and unprotected group ([[43]](#mehrabi2021))
[^20]: It deals with the fairness of the decision-making process that leads to the outcome in question ([[54]](#grgichlaca2018))

